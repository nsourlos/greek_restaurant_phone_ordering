{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "# from langchain.evaluation.qa import QAGenerateChain\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file with OpenAI key\n",
    "\n",
    "#Set API keys for OpenAI and Cohere embeddings\n",
    "openai.api_key = openai_api_key=os.environ['OPENAI_API_KEY']\n",
    "cohere_api_key = os.environ['COHERE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[]\n",
    "for file in os.listdir('./number_one_menu/final_best_with_GPT/'):\n",
    "    if 'final_' in file and 'final_website_preprocessed' not in file:\n",
    "        with open('./number_one_menu/final_best_with_GPT/' + file, 'r', encoding=\"utf8\") as f:\n",
    "            documents.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some changes in the menu\n",
    "for ind, doc in enumerate(documents):\n",
    "    if 'Κλασσική' or 'κλασσική' in doc:\n",
    "        documents[ind] = doc.replace(\"Κλασσική\", \"πίτα\" )\n",
    "        documents[ind] = doc.replace(\"κλασσική\", \"πίτα\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100) #chunk_size refers to characters, not tokens! Initially set to 1000,200\n",
    "# Split your documents into texts\n",
    "texts = text_splitter.create_documents(documents)\n",
    "\n",
    "#Turn your texts into embeddings\n",
    "# embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key,model='text-embedding-ada-002') #Alternative option (cheap but not free)\n",
    "embeddings = CohereEmbeddings(model = \"multilingual-22-12\", cohere_api_key=cohere_api_key)\n",
    "#Taken from #https://txt.cohere.com/search-cohere-langchain/\n",
    "#Cohere Free tier limits: https://docs.cohere.com/docs/going-live\n",
    "#Information about OpenAI embeddings: https://platform.openai.com/docs/guides/embeddings\n",
    "\n",
    "#Get your docsearch ready\n",
    "docsearch = Qdrant.from_documents(texts, embeddings,location=\":memory:\",  collection_name=\"my_documents\", distance_func=\"Dot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates examples in English due to langchain prompt\n",
    "\n",
    "# example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI())\n",
    "\n",
    "# new_examples = example_gen_chain.apply_and_parse(\n",
    "#     [{\"doc\": t} for t in documents[:5]]\n",
    "# )\n",
    "\n",
    "# new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual examples\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Θα ήθελα να παραγγείλω 3 σουβλάκια κοτόπουλο με σως\",\n",
    "        \"answer\": \"Τα 3 σουβλάκια κοτόπουλο με σως κοστίζουν €6.00\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Θα ήθελα μια αμστελ\",\n",
    "        \"answer\": \"Η μπύρα αμστελ 330ml κοστίζει €2.00\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soyrl\\.conda\\envs\\order_test\\lib\\site-packages\\langchain\\llms\\openai.py:171: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\soyrl\\.conda\\envs\\order_test\\lib\\site-packages\\langchain\\llms\\openai.py:739: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Predictions \n",
      " [{'query': 'Θα ήθελα να παραγγείλω 3 σουβλάκια κοτόπουλο με σως', 'answer': 'Τα 3 σουβλάκια κοτόπουλο με σως κοστίζουν €6.00', 'result': 'The cost of each souvlaki chicken with sauce is €2.00. Therefore, the total cost for 3 souvlaki chicken with sauce would be €6.00.'}, {'query': 'Θα ήθελα μια αμστελ', 'answer': 'Η μπύρα αμστελ 330ml κοστίζει €2.00', 'result': \"I don't know.\"}]\n",
      "Examples \n",
      " [{'query': 'Θα ήθελα να παραγγείλω 3 σουβλάκια κοτόπουλο με σως', 'answer': 'Τα 3 σουβλάκια κοτόπουλο με σως κοστίζουν €6.00'}, {'query': 'Θα ήθελα μια αμστελ', 'answer': 'Η μπύρα αμστελ 330ml κοστίζει €2.00'}]\n"
     ]
    }
   ],
   "source": [
    "#Get predictions\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(openai_api_key=openai_api_key,temperature=0, request_timeout=9,max_retries=1, model_name='gpt-3.5-turbo'), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(k=1), \n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "predictions = qa.apply(examples)\n",
    "\n",
    "print(\"Predictions \\n\",predictions)\n",
    "print(\"Examples \\n\",examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'CORRECT'}, {'text': 'INCORRECT'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate predictions\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "eval_chain = QAEvalChain.from_llm(llm)\n",
    "graded_outputs = eval_chain.evaluate(examples, predictions)\n",
    "graded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: Θα ήθελα να παραγγείλω 3 σουβλάκια κοτόπουλο με σως\n",
      "Real Answer: Τα 3 σουβλάκια κοτόπουλο με σως κοστίζουν €6.00\n",
      "Predicted Answer: The cost of each souvlaki chicken with sauce is €2.00. Therefore, the total cost for 3 souvlaki chicken with sauce would be €6.00.\n",
      "Predicted Grade: CORRECT\n",
      "Example 1:\n",
      "Question: Θα ήθελα μια αμστελ\n",
      "Real Answer: Η μπύρα αμστελ 330ml κοστίζει €2.00\n",
      "Predicted Answer: I don't know.\n",
      "Predicted Grade: INCORRECT\n"
     ]
    }
   ],
   "source": [
    "#Detailed comparison of predictions with their labels\n",
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate variations of items in menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make each element in the list being an item from the menu - Does not work well with embeddings, needs more context\n",
    "documents_final=[]\n",
    "longest_text=0\n",
    "for text in documents:\n",
    "    text = text.split('\\n')\n",
    "    for item in text:\n",
    "        documents_final.append(item) #Get each item of menu as an element of list\n",
    "        if len(item)>longest_text:\n",
    "            longest_text=len(item) #Will be ~175 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Παρακάτω δίνεται ένα προϊόν που υπάρχει στο μενού ενός εστιατορίου. Βρες μια εναλλακτική φράση για το προϊόν που μπορεί ένας πελάτης να πει όταν \\\n",
    "θέλει να το παραγγείλει, παραφράζοντάς το όταν είναι δυνατό, ή αλλάζοντας μερικές λεπτομέρειες από αυτό. \\\n",
    "Για παράδειγμα, αντί για '3 σουβλάκια χοιρινά' ο χρήστης μπορεί να πει '3 χοιρινά με σως' και αντί για  \\\n",
    "'halloumi burger (μοσχαρίσιο, χαλούμι, ρόκα, ντομάτα, μαγιονέζα)' μπορεί να πει 'χαλούμι μπέργκερ με ντομάτα και μαγιονέζα'. Απάντησε μόνο με την φράση του χρήστη η οποία \\\n",
    "πρέπει να περικλείεται με << >>. Το προϊόν είναι:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM variation: <<Θα ήθελα ένα amstel 330ml, παρακαλώ.>>\n",
      "Actual label: amstel 330ml - €2.00\n",
      "LLM variation: <<Θα ήθελα ένα Amstel 500ml παρακαλώ, τιμή 2.40 ευρώ.>>\n",
      "Actual label: amstel 500ml - €2.40\n",
      "LLM variation: <<Θα ήθελα μια coca cola 1,5 λίτρου, παρακαλώ.>>\n",
      "Actual label: coca cola 1500ml - €3.00\n",
      "LLM variation: <<Μια κόκα κόλα στα 330ml, παρακαλώ.>>\n",
      "Actual label: coca cola 330ml - €1.60\n",
      "LLM variation: <<Μια coca cola 500ml, παρακαλώ.>>\n",
      "Actual label: coca cola 500ml - €1.80\n",
      "LLM variation: <<Θα ήθελα ένα coca cola light 330ml, παρακαλώ.>>\n",
      "Actual label: coca cola light 330ml - €1.60\n",
      "LLM variation: <<Θα ήθελα μια μεγάλη κόκα κόλα light 1500ml, παρακαλώ.>>\n",
      "Actual label: coca cola zero 1500ml - €3.00\n",
      "LLM variation: <<Μία zero κόκα κόλα παρακαλώ, 330ml>>\n",
      "Actual label: coca cola zero 330ml - €1.60\n",
      "LLM variation: <<Θα ήθελα μια coca cola zero 500ml, παρακαλώ.>>\n",
      "Actual label: coca cola zero 500ml - €1.80\n",
      "LLM variation: <<Θα παραγγείλω ένα φαντα λεμονίτα 330ml, παρακαλώ.>>\n",
      "Actual label: fanta λεμονίτα 330ml - €1.60\n",
      "LLM variation: <<Θα ήθελα μία πορτοκαλάδα fanta 1500ml, παρακαλώ.>>\n",
      "Actual label: fanta πορτοκαλάδα 1500ml - €3.00\n",
      "LLM variation: <<Θα ήθελα μια fanta πορτοκαλάδα με ανθρακικό 330ml, παρακαλώ.>>\n",
      "Actual label: fanta πορτοκαλάδα με ανθρακικό 330ml - €1.60\n",
      "LLM variation: <<Ένα μοσχαρίσιο μπέργκερ με χαλούμι, ρόκα, ντομάτα και μαγιονέζα, παρακαλώ.>>\n",
      "Actual label: halloumi burger (μοσχαρίσιο, χαλούμι, ρόκα, ντομάτα, μαγιονέζα) - €5.30\n",
      "LLM variation: <<Θα ήθελα έναν αριθμό 1 μπέργκερ με τυρί cheddar, αυγό, μαρούλι, ντομάτα και κρεμμύδια>>.\n",
      "Actual label: number 1 burger (μοσχαρίσιο, διπλό cheddar, αυγό τηγανητό, μαρούλι, ντομάτα, καραμελωμένα κρεμμύδια) - €5.50\n",
      "LLM variation: <<Θα ήθελα ένα γαριδομπέργκερ με ντομάτα, κρεμμύδι, μαρούλι, αβοκάντο και σως cocktail.>>\n",
      "Actual label: shrimp burger (παναρισμένη γαρίδα, ντομάτα, κρεμμύδι, μαρούλι, αβοκάντο, σως cocktail) - €5.20\n",
      "LLM variation: <<Θα ήθελα ένα burger που θα φτιάξω εγώ, παρακαλώ.>>\n",
      "Actual label: φτιάξε το δικό σου burger! - €0.80\n",
      "LLM variation: <<ένα μοσχαρίσιο hamburger με αγγουρομαγιονέζα και κετσαπ, παρακαλώ>>\n",
      "Actual label: hamburger (μοσχαρίσιο, ντομάτα, κετσαπ, αγγουρομαγιονέζα) - €3.60\n",
      "LLM variation: <<Ένα cheese burger με τυρί, ντομάτα και κετσαπ, παρακαλώ.>>\n",
      "Actual label: cheese burger (μοσχαρίσιο, τυρί, ντομάτα, κετσαπ, αγγουρομαγιονέζα) - €3.90\n",
      "LLM variation: <<Θα παραγγείλω ένα super burger με μοσχαρίσιο και παρμεζάνα, χωρίς μπέικον, με κετσαπ και αγγουρομαγιονέζα.>>\n",
      "Actual label: super burger (μοσχαρίσιο, ντομάτα, μπέικον, παρμεζάνα, κετσαπ, αγγουρομαγιονέζα) - €4.00\n",
      "LLM variation: <<Θα ήθελα ένα mega burger με διπλό μοσχαρίσιο, μπέικον, κρεμμύδι, τυρί, μαρούλι, κετσαπ και μαγιονέζα. Μπορείτε να το συνοδεύσετε με πατάτες και σως; Πόσο κοστίζει;>>\n",
      "Actual label: mega burger (διπλό μοσχαρίσιο, διπλό τυρί, μπέικον, μαρούλι, κρεμμύδι, ντομάτα, κετσαπ, μαγιονέζα. συνοδεύεται με πατάτες, σως) - €7.90\n"
     ]
    }
   ],
   "source": [
    "examples = [{} for i in range(len(documents_final))]\n",
    "\n",
    "for i in range(20): #~570 items in menu\n",
    "    retrieved_menu=documents_final[i]\n",
    "    llm=OpenAI(openai_api_key=openai_api_key,temperature=0.9,model_name='gpt-3.5-turbo')\n",
    "    response_final=llm.predict(prompt+retrieved_menu) #Predict response using LLM GPT 3.5 turbo\n",
    "    print(\"LLM variation:\",response_final)\n",
    "    print(\"Actual label:\",retrieved_menu)\n",
    "    examples[i]['query']=response_final\n",
    "    examples[i]['answer']=retrieved_menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above variations can also be added to menu to make it easier for LLM to retrieve them when order is placed. Not sure if it helps. Not done yet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "order_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
